import streamlit as st
from huggingface_hub import InferenceClient
from PIL import Image
import io

# --- è¨­å®š ---
MODEL_ID = "runwayml/stable-diffusion-inpainting"

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIèƒŒæ™¯æ‹¡å¼µ", layout="wide")
st.title("ğŸ¨ AIåºƒå‘Šç”»åƒãƒ¡ãƒ¼ã‚«ãƒ¼ (èƒŒæ™¯æ‹¡å¼µ)")
st.markdown("""
ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è¶³ã‚Šãªã„èƒŒæ™¯ã‚’AIãŒè‡ªå‹•ã§æãè¶³ã—ã¾ã™ã€‚
Hugging Faceã®ç„¡æ–™APIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
""")

# --- ã€å¤‰æ›´ç‚¹ã€‘Secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ ---
try:
    # Streamlit Cloudã®Secretsã‹ã‚‰å–å¾—
    api_token = st.secrets["HF_TOKEN"]
except Exception:
    st.error("âš ï¸ è¨­å®šã‚¨ãƒ©ãƒ¼: APIãƒˆãƒ¼ã‚¯ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Streamlit Cloudã®Settings > Secrets ã« 'HF_TOKEN' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop() # ã‚­ãƒ¼ãŒãªã„å ´åˆã¯ã“ã“ã§åœæ­¢

# --- é–¢æ•°: AIã«ã‚ˆã‚‹èƒŒæ™¯æ‹¡å¼µ ---
def ai_expand(api_token, image, target_w, target_h):
    client = InferenceClient(token=api_token)
    orig_w, orig_h = image.size
    
    # 1. ã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆ
    scale = min(target_w / orig_w, target_h / orig_h)
    new_w = int(orig_w * scale)
    new_h = int(orig_h * scale)
    resized_img = image.resize((new_w, new_h), Image.LANCZOS)
    
    background = Image.new("RGB", (target_w, target_h), (0, 0, 0))
    paste_x = (target_w - new_w) // 2
    paste_y = (target_h - new_h) // 2
    background.paste(resized_img, (paste_x, paste_y))
    
    # 2. ãƒã‚¹ã‚¯ä½œæˆ
    mask = Image.new("L", (target_w, target_h), 255)
    mask_keep = Image.new("L", (new_w, new_h), 0)
    mask.paste(mask_keep, (paste_x, paste_y))
    
    # 3. ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    prompt = "high quality background, seamless extension, photorealistic, 4k, cinematic lighting, no text"
    negative_prompt = "text, watermark, low quality, distorted, blurry, ugly, bad anatomy, frame, borders"

    try:
        output_image = client.text_to_image(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=background,
            mask_image=mask,
            model=MODEL_ID,
            height=target_h,
            width=target_w,
            num_inference_steps=25,
            guidance_scale=7.5,
        )
        return output_image
    except Exception as e:
        st.error(f"ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['jpg', 'png'])

if uploaded_file:
    input_image = Image.open(uploaded_file).convert("RGB")
    
    st.divider()
    
    if st.button("ğŸš€ AIç”Ÿæˆé–‹å§‹"):
        # å®‰å…¨ã®ãŸã‚ã‚µã‚¤ã‚ºã¯æ§ãˆã‚ã«
        targets = [
            (512, 512, "æ­£æ–¹å½¢"), 
            (768, 432, "æ¨ªé•·"), 
            (600, 400, "ãƒãƒŠãƒ¼")
        ]
        
        cols = st.columns(3)
        
        for i, (w, h, label) in enumerate(targets):
            with cols[i]:
                st.write(f"â³ {label}...")
                result_img = ai_expand(api_token, input_image, w, h)
                
                if result_img:
                    st.image(result_img, use_container_width=True)
                    buf = io.BytesIO()
                    result_img.save(buf, format="JPEG", quality=95)
                    st.download_button(
                        label="ä¿å­˜",
                        data=buf.getvalue(),
                        file_name=f"ai_bg_{w}x{h}.jpg",
                        mime="image/jpeg"
                    )
